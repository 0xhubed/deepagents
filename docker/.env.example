# DeepAgents Docker Environment Configuration
# Copy this file to .env and customize as needed

# ============================================
# OLLAMA CONFIGURATION (Required)
# ============================================

# URL of your Ollama server (without /api/chat - the library adds that)
OLLAMA_BASE_URL=http://10.8.137.71:11435

# Default model to use
# Available models on your server: gpt-oss:20b, glm-4.7-flash:latest
OLLAMA_MODEL=gpt-oss:20b

# ============================================
# ALTERNATIVE MODELS
# ============================================

# Uncomment to use a different model:
# OLLAMA_MODEL=glm-4.7-flash:latest

# ============================================
# CLOUD PROVIDER FALLBACKS (Optional)
# ============================================

# If Ollama is unavailable, the agent can fall back to cloud providers
# Uncomment and fill in API keys if you want this fallback behavior

# OpenAI
# OPENAI_API_KEY=sk-...
# OPENAI_MODEL=gpt-4

# Anthropic (Claude)
# ANTHROPIC_API_KEY=sk-ant-...
# ANTHROPIC_MODEL=claude-sonnet-4-5-20250929

# Google (Gemini)
# GOOGLE_API_KEY=...
# GOOGLE_MODEL=gemini-pro

# ============================================
# OPTIONAL FEATURES
# ============================================

# Tavily API for web search capability
# TAVILY_API_KEY=tvly-...

# LangSmith for debugging and tracing (useful for development)
# LANGCHAIN_TRACING_V2=true
# LANGSMITH_API_KEY=ls-...
# LANGSMITH_PROJECT=deepagents-local

# ============================================
# NOTES
# ============================================

# Priority order when no model is specified:
# 1. Ollama (if OLLAMA_BASE_URL is set)
# 2. OpenAI (if OPENAI_API_KEY is set)
# 3. Anthropic (if ANTHROPIC_API_KEY is set)
# 4. Google (if GOOGLE_API_KEY is set)
#
# To force a specific provider, use the --model flag:
#   deepagents --model "ollama:gpt-oss:20b"
#   deepagents --model "ollama:glm-4.7-flash:latest"
